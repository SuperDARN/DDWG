# DDWG meeting Minutes: June 3 2020 12:00 - 15:25 UTC

Day| Date | Time | Location| Next Meeting
|---|---|---|---|---|
| Wednesday| June 1 2020 | 12:00 - 15:25 UTC | Webex | TBD |

```
Minutes will appear as text in this format

Action items to come from this meeting:

1) Kevin Krieger/USASK:
    Share results of audit
    Reconcile issue numbers on github with historical issues
    Check consistency of responsibilities section with the PI agreement
    Check with DSWG about data level definitions, to make sure we are consistent with their docs
    Keep track of which files were converted from RAWACF and place in separate directory to 'dat'
    Make available a list of 'fixed' files alongside blacklist and failed files lists
    Step 6 for gap resolution: Inform DDWG of old files added
    Add to charter old file formats such as FIT that are also in the distribution (if any)
    Send message asking group to look for missing DAT files and original

2) DAWG:
    Provide tool for checking DAT files similar to the tool for checking RAWACF files
    Provide tool for checking RAWACF files that were converted to DAT with low-pwr issue
    Provide tools for fixing blacklisted files
    Provide guidance on possible fixes to DCN files that had phasing matrix issue

3) Kevin Sterne/Paul Breen/DDWG members who stage files for them:
    Work to get all PI institutions' radar data flowing to both VT and BAS

4) Data Policy Task Force:
    Inform DDWG of appropriate responsibilities and policies
    Who is responsible for fixing files?
    Should the DDWG be placing higher level data products in the scope?

5) PIs:
    Provide access to the latest PI agreement

5) DSWG:
    Add categories for blacklisting to level 1 standard documentation
    Provide guidance on data product level definitions (level 0, level 1, etc)

```

## Attendees
| Name | Institution | Shorthand | Present? |
| --- | --- | --- | --- |
| Kevin Krieger [Organizer] | USASK| KKr | x
| Marci Detwiller | USASK | MD | x
| Marina Schmidt [Minutes] | USASK |  MSc | x
| Keith Kotyk | USASK |  KKo |
| Kevin Sterne | VT |  KS | x
| Simon Shepherd | Dartmouth | SS | x
| Evan Thomas | Dartmouth |  ET | x
| Akira Sessai Yukimatu | NIPR | ASY | x 
| Yuka Kadowaki | NIPR | YK 
| Jordan Wiker | JHU/APL | JWi | x
| Enrico Simeoli | IAPS/INAF | ES | x  
| John Devlin | LaTrobe | JD  
| Jim Whittington | LaTrobe | JWh  
| Mark Gentile | LaTrobe |  MG
| Andrew McDonald | LaTrobe | AMcD 
| Paul Breen | BAS | PB | x
| Tim Barnes | BAS | TB | x
| Bill Bristow | UAF/Penn State |  BB | x
| Jianjun Liu | PRIC | JL | x
| Hongqiao Hu | PRIC | HH
| Judy Stephenson | UKZN | JS | x 
| Tomoaki Hori | ISEE | TH
| Nozomu Nishitani | ISEE | NN  | x
| Aurélie Marchaudon | IRAP |  AMa | x
| Tsutomu Nagatsuma | NICT | TN
| Keisuke Hosokawa | UEC | KH
| Chris Thomas | Leicester |  CT 
| Tim Yeoman | Leicester |  TY | x
| Adrian Grocott | Lancaster | AG | x
| Wei Wang | NSSC | WW | x
| Mikko Syrjäsuo| UNIS | MSy | x
| Zanyang Xing | SDU | ZX | x
| Qinghe Zhang | SDU | QZ
| Mike Ruohoniemi | VT | MR
| Kathryn McWilliams | USASK | KMcW | x
| Dieter Andre | USASK | DA
| Jean-Pierre St.Maurice | USASK| JP
| Federica Marcucci | IAPS/INAF | FM | x


## General Announcements - 10 minutes

1. Kevin Sterne: VT Will have an extended outage (maybe a day or week or longer) 
sometime this summer.
1. DDWG Github repository will now be used to keep track of DDWG tasks, issues, etc.
1. hdw.dat files are not within the scope of DDWG
1. Activities over the past year
    1. Sessai and Yuka found many DAT files from 1999 (it was suspected they were missed because 
    they had a non-standard name, the first two digits of the year were missing)
    1. Evan found that some DAT files that were listed as missing actually just had differing 
    case on some characters, and these files were retrieved from VT's archive
    1. Judy uploaded many SAN DAT files from 1999
    1. Blacklisted/removed files made available via Globus 'deletions' directory
    1. Compute Canada allocation awarded, we now have 85TB (then 90 and 95 TB the next two years)
    1. Audit performed, thank you for your feedback
    1. FITACF 3.0 files available on request via Globus 
    1. Data gaps for September 2017 to August 2019 checked
    1. Evan uncovered an issue with DAT hashes files that was fixed by Kevin
    1. New radars added to the distribution: DCN and JME
    1. Evan and Paul worked to fill in some gaps of data on the BAS server

```
Kevin Sterne: A relocation of the facility will be a cause of downtime this summer between a couple
of days to a month.

Simon: Why was audit performed and can we see the results?
KKr: Done to get a better understanding of how groups do data mgmt. I can place a summary on github

Simon: Merging is a complete set to upload files so it may be meaningless now:
KKr: Merging in this context means to go onto one of the repository locations since all data is 
coming from different sources, perhaps we need to reword this section

```

## DDWG Discussion topics

#### Charter update and review - 30 minutes
1. Review scope & purpose of DDWG (keeping in mind DAWG and DSWG)
1. Review communications channels
1. Review responsibilities of members/observers/chairs or co-chair(s)
1. Review types of members

```
Aurélie: What about higher level data products? [in reference to the purpose]

KS: What is the thought on higher level data products?

KKr: Currently DDWG is only responsible for level 1, perhaps the PIs can discuss the possibility
of the DDWG including higher level data products

KS: Noted in PI agreement there is no mention of FITACF files

KMcW: FITACF 3.0 are exposed via globus API, but not part of DDWG as we are using the globus 
allocation just to host them for local scientists

Evan: What about FIT files created at radar sites stored on globus, but not BAS, wonder what the plan
is for those?

KKr: Don't have a plan to remove them, not aware if current radars are still producing FIT files.

Paul: Avoiding FIT/FITACF due to management time

KS: Don't have time for higher level products either  

KKr: Note that communication will still be done via the mailing list, but the git repo will
be a landing place for all issues and documents, convenient for my workflow.

KKr: Most tasks are automated already on my end

Paul : Same, most everything that was possible to automate has been automated

KS: Same, most everything automated

Simon: How often are files added to distribution?

KKr: not in charter, but ideally every 2 hours (but some radars have issues with networks, so obviously
would need to be less frequent) See FAQ

Simon: Just because they get to one place doesn't mean they are accessible by everyone

Federica: Quote from PI agreement: "Principal Investigators agree to provide their complete level 1 
data sets via direct internet access to an agreed institution on a daily basis, or as regularly and 
as soon as possible as the available technology or resources allows."

Bill:Is this something that the charter for the working group should address. I thought the charter 
was intended to tell the WG what they should be doing, not telling the PIs what they should be doing. 
That’s the PI agreement  

Simon: there is a lot of steps to uploading files to the servers/holding institutes and the this 
charter is about making what is uploaded to the other institutes to a reasonable time. Laying out 
how the members should take on responsibilities to keep the flow chart going. 

Bill: Agreed. The charter should lay out that the WG should make the data available as quickly as 
possible. PIs should upload the data and DDWG should focus on making it available as fast as possible. 

KKr: Agree 

Kathryn: That can be in the future Data Policy (in devel)

Simon: asking for Clarification on the Data Policy.
 
Kathryn: Data policy would be a higher level policy to layout everyone's responsibilities in terms 
of data and meta data. And the Working Groups layout the procedures of how that is done. 

KS: Brought up the concern in the definitions on level 0 and 1 data and wondering if that is 
correct after the DSWG meeting and maybe should be defined by them and if it should be defined here.  

KKr: Correct, I will make a note to check on that with DSWG, to keep our doc consistent with the 
data level numbers
 
```
#### Policies update and review - 30 minutes
1. Raising issues
1. Blacklisting files
1. Checking files
1. Updating files
1. Addition of old files
1. Removing files
1. Record-keeping/backups
1. Gap resolution
1. Reporting

```
KKr: Issues raised via mailing list can be archived on globus and issues raised on globus can be
disseminated/summarized via mailing list

AM: How often are issues raised?
KKr: About ~37 issues in total, the number of issues is tapering off though
AM: Can someone fill in issues on Globus as they come in via mailing list?
KKr: Yes this can be done, the plan is for github to store issues

KKr: Policy/procedures is a high level view of how we deal with the data. DDWG not responsible for
the software tools that are used to check data, but responsible for using them and making sure
the files in the distribution pass all checks.

Evan: Should there be checks on dat files too? 

KKr: Yes, is there a tool?

Evan: There should be some resources allocated to that and RST might have some but we can as DAWG 
put something together.

Simon: I don't think it is responsiblility for this group to fix the blacklisted files but if there 
is a way to tell what is wrong with it and maybe someone can apply the fix to it. 

Mikko: Is there a list of reasons for blacklisting data? Could we have that in github so that if 
somebody comes up with a solution, then somebody else might be use the same solution.

KKr: We don't have a list but it can be anything really, but the PIs usually give the reason. 
Any technical or scientific reason can be the cause. 

Bill: usually blacklisted files happens to a blip in the power and it corrupts the last record. 
Smart programmer can trim the record out.

Evan: mentioned RST has a feature to trim records 

Marci: DSWG could come up with a blacklisted list of reasons and then help direct how to fix them. 

Simon: Noted that there is a long list and it is ever growing but documenting would be good. 
Also, wasn't there a website that listed groups of files on why they were listed? 

KKr: Yes and we can link github issue with the reason so people can understand the issue why they 
were blacklisted.

Kathryn: Do blacklisted files include those that were fixed and the correct versions added to main 
distribution? If so, then they don't need future fixes.

KKr: No if there are fixed they are removed from the blacklist

Evan: Would they have different hashes?

KKr: Yes, Blacklisted files will not have a specific hash just a name and if an updated file comes 
in then the updating file will have different hash, and updated files list will have specific hashes  

Simon: I don't want to complicate anything... but can you create a second file "fixed" that contain 
a list of the files that were blacklisted and fixed?

KKr: That is a small subset of files and but no problem making that available.
 
Simon: Speaking to Kathryn's comment this may be useful to track the blacklisted files that are 
fixed as we start thinking about it. 

KKr: There is a list of updated files. But this doesn't happen very often.  

KKr: File checking: This is something we started doing to get a handle on Quality control.
We check file sizes to see if they are empty and if there is corruption.

Paul: Currently on the BAS we don't DMAP check, we cannot get the DMAP check to work on our VMs 
with backscatter pacakage due to python.
 
Marina: try pyDARN if you have python 3 

Paul: We will be doing a OS upgrade so maybe try then again 

Federica: Sorry for the late reaction, in the DCE case we had a problem with the Phasing Matrix, 
I do not think it can be easilly fiked in the data, but 6 months of data are affected and it would 
be worth that the communitiy has some info about and If someone has a solution to use those data, 
for some specific interval at least, it would be good

Simon: Can we not check at local computers or at globus then sync back to BAS. 

KKr/Kathryn: We can but if some one doesn't check and it gets out how do we handle that.
 
Simon: Also, if a server goes down how does that affect us, we should be routing to multiple 
servers so we don't bottleneck. 

KKr: Agreed, believe all PI groups should send data to both VT and BAS 

KKr: check for pre-commission data: haven't gotten to this but this is what should be done.

Evan: Clarify pre-commission data date

KKr: something earlier than the PI wanted on the distribution from the radars start date. 

KKr: Updating files: order is important here

KKr: Adding of old Files, how old is an 'old' file? Send email if files are xx days old
 
Simon: Agrees to it since he brought it up

KKr: What is an appropriate timeline?

Simon: It would convenient to get some notification on the number of files getting received. 

KS: Main driver, is I place it at 2 months. Generally is the time to get IMF data. 
When I get something 2 months older then it sends me an email to know when to regenerate a map file. 

Paul: BAS also has this 2 month cut off, then will mark those records as being old. 
The BAS catalogue marks as "old" because they came in past 2 month mark. 

Bill: Is there something like a txt file and see if there is descrepencies to check so they can 
download the file? 

KKr: Yes there is. (goes to FAQ.md reads out the "How can I see what data is available on the 
mirrors?")

Simon: there is a very nice graphical display for the BAS server

Bill: I want something I can automate...the hash files would be great  

Simon: http://bslsuperdarnc.nerc-bas.ac.uk/apps/sd-cat/

KKR: Record Keeping/backups: this is something that should be done, to have a policy for what needs
to be logged.  

KKr: Gap Resolution: Add step 6 to inform the WG about old files being added in
 
Aurelie: do people reply on a reasonable time?

KKr: people generally reply within 2 weeks, usually everyone replies 

Annual Report
Evan: Is there a report this year?

KKr: Not yet

[10 minute BREAK, reconvene at 07:10 UTC]
```
#### Any issues with radar data not properly distributed to VT/USASK/BAS - 30 minutes 
From Simon: 
1. What is the purpose of 'holding' institutions? Do they add anything, other than another
point of failure and overly complicating the system?
1. Why are data from some radars distributed to both servers (are they?) but not all?
1. Do we want additional servers and which data do they get?
1. How can we reduce manual processes necessary to keep things running properly (data flow 
and synchronization between servers?)

```
Simon: Is the data flow correct?

KKr: I believe so, KS just updated
 
Paul: Not quite correct, sye, sys now setup from NIPR

Nozomu: hok and hkw data are supplied to both VT and BAS

Judy: san goes to BAS and VT

Aurelie: ker is going to BAS and VT as well

KS: Many lines missing due to make the flow chart more simple 

Simon: This is an overally compilicated process. Is the best we can do? There is several single 
point failures in the last few months. 

Bill: Agrees we should simplify
 
Bill: [in reference to files going to multiple institutions] That’s how it should be. Get some 
redundancy in

Simon: Points out this is a legacy system, If I was drawing this out I would have my data going 
to globus and BAS servers. Datmouth could be a server as well. Past few months when the data 
stopped it was hard to figure out where it was. 

KKr: Agreed I personally think all PI groups should send their data to both places 

Simon: Dartmouth could be a server but not sure I want to do that. 

KKr: yea that would be great if you opened up another server, need to be aware of the work involved

Evan: If the central block (ie the temporary mirror) disappears, what is the plan for getting data 
from VT to BAS?

Paul: It has to be raised as a project and we need upgrade the OS to get the globus python sdk working. 

Bill: Can we set up something quickly to bypass VT?

KKr: Can you explain that more

Bill: While VT is down is there a way we can get it fed into another server like USASK?

KS: spreading out the work flow. 

KKr: where are going to put these resources? KS spends time maintaining the system in place, if that
is removed then someone else has to pick up slack 

Simon: I don't know if it is resources, and I could do some things. Is there a way to simplify it. 

Evan: it seems like we need a direct two-way arrow between the two colored blocks on this diagram

KKr: Need to wait until BAS has an upgrade to OS so they can get globus data 

Simon: If we set up a server maybe we don't need to do that? I am asking the community to setup 
another server. 

Kathryn: Currently USASK is having an issue with getting rsync to be allowed and BAS has python 
issues. 

Simon: I am not volunteering but setting up more servers to have several mirrors. Concerned 
we have to use globus. 

Aurelie: How do you think this will help? A lot of groups don't have funding, 
time or resources for it. We should work with what we have.

Kathryn: Idealy we should expand our system to be flexible to add other servers at some point. 

Simon: BAS mirror is easier to use then globus 

Paul: If we can upgrade to our OS we would use globus to syn can we would offer rsync. 
It shouldn't be under estimated to be setting up the systems. We are doing the best we can. 

Kathryn: We would like to have more resources and servers. Japanese colleagues were unable to get it 
too because of a lack of resources. 

Paul: Its a moving target, that things are always changing and there is more effort to add in more 
servers. 

Kathryn: There's a tradeoff with the simplicity vs. time and keeping it running. 

Paul: Agreed 

KKr: to summarize: resources are limited and we are doing what we can with what we have. 
And we should deal with with the VT downtime this could happen. 

KS: Maybe 4-5 days but do not know if it will be longer.  Currently no date set and wasn't trying 
to scare people with the downtime. 
  
Federica: Probably is almost impossible to implement, but we should at some point think if we 
could ask for funding as a community 

Kathryn: Any EU sources, as an example?

Federica: we are an international important infrastructure

Aurelie: we have to check the next H2020 callls, I suppose, but don't forget that once the grant 
is finished, no more support (especially human ressources)

Why are data from some radars distributed to both servers but not all?
KKr: I agree data should go to both servers but it will add work to Sterne and Paul 

Paul: I agree but as long as the staging mechanism we have done before then it won't be difficult. 
However, the accounts and access is difficult is done then should be easy after that. So in that 
sense its not a huge amount of work and doable. 

KS: Might have some time to do this? 

KS: the diagram it doesn't show everything. A lot of things we do already. But BAS is suppose 
to take care of the EU sector and that is why I am not downloading from them. 

KKr: I know some of those radars would be able to sync to both institutions. 

Mikko (chat): It is no problem to add access for you to get LYR data the same BAS does it now... :-)

Paul: Originally it was seen to portion out the institutes to specific servers. But now I think we 
need to send it to both servers. 

Simon (chat): Excellent! I will be sending data to BAS

Bill (chat): Not a big impact 

Federica (chat): To Aurèlie, you are right, but perhaps things can change in the future if we make 
a link to the space weather activities. I'm not sure as I said if this can be implemented, but it is 
worth I think just to investigate...

Aurelie (chat): Sure :)

KKr: choppy audio...  

Simon: this has been discussed already and to allow flow to both servers. 

KKr: if it is possible to automate all uploads that would be great
```

#### Mirror sync issues - 30 minutes
1. Evan has produced lists of files (20200521)
    1. Files that are on Globus, but not at BAS (~11,400)
    1. Files that are at BAS, but not Globus (~800 files)

```
KKr: the missing files on globus but not BAS might be failure from DMAP checks. Need to look at 
these files to double check. Files on Globus and not on BAS is due to the past few months with 
the server issues.

Evan: The events with drops in servers cause these discrepancies 

Kevin: TODO list to see why they are on one server but not the other. Evan, Did you write a script
[to fill in gaps with Paul on BAS server)? 

Evan: IT won't put globus on our server and I had to use my laptop and was very difficult to do so. 
Not offering to do this again as it was a lot time and trouble. 

Nozomu (chat): Evan, how much of them are from hkw? I suppose that it was due to assigning wrong 
blacklist period and it was already solved.

Evan (chat): These were pre-rawacf, so 2006 or earlier I think

Evan: there is missing dat files between servers

Evan: Blacklisting issue has been corrected now on both BAS and USASK servers. 

Paul(chat): That was fixed in BAS only recently. 

KKr: Same, fixed them last year. TODO to spend some time looking over the files and why they are 
difference between Globus and BAS. 

Evan: A lot of dat files converted to RAWACF, this made it hard to compare hashes as they are only 
on globus. The date times are not correct times on the file names, need to look at first record.

KKr: What are the issues with having both dat and rawacf?

Evan: If user is syncing all files they would get dat and rawacf files and be unaware.

Simon: your converting dattorawacf then distributing them. I don't know this is correct for this WG. 
As long as we know this process was done correctly. 

KS: I am the guilty party of for screwing up the naming convention. I agree that RAWACF from 
dat files should be distributed. What is the concern? If you are downloading them all that could be
an issue but the space shouldn't be an issue.

Evan: it is okay to this conversion but maybe make sure it done correctly and be better to track 
some way to be aware

KKr: agree, could place into a parallel directory that is properly/clearly named 

KS: Fairly sure that dattorawacf stores in the origin.command an appropriate string in the 
RAWACF file. 

KKr: agreed to putting in different directories 

```
#### Metadata/context for removed files - 10 minutes
1. Federica brought up a suggestion, regarding the blacklisted/removed files that are 
now available on Globus in a parallel directory to the main distribution, as of August 20 2019.

"
I’m wondering if it could be useful that a bit of information on why the data 
are there is made available as well (or perhaps to explicitly indicate, in some way,
to contact the PI for further information in case one is particularly keen on using
those data). Not sure, however, how this can be realized
"

#### How do we ensure that corrected data is distributed through PI institutions?  - 10 minutes

Currently, when corrected files are placed on the mirror, the policy is to inform
the DDWG through the mailing list, and to suggest that any higher level data products need to 
be reproduced. There is no feedback loop here to know that this is actually happening.

Is this an issue? How do we ensure that everyone is up-to-date?

```
Group agrees to using the mailing list to notify on data files and issues. 
```

## Data Issues

#### `dattorawacf` concerns - 10 minutes

Evan brought up this issue and his description is below. In summary, the `dattorawacf` 
program has been updated (see [this](https://github.com/SuperDARN/rst/issues/142)), and any 
files that were processed from DAT to RAWACF with the old version need to be reproduced 
with the new version. However, those original DAT files (UNW and STO) still need to be found.

"
I've just spot checked a random UNW rawacf file (20120217.1400.00.unw.rawacf) from the BAS 
mirror and compared the dmapdump contents to the output of a dattorawacf command using the 
original dat file on VT's server. As expected, the slist parameter (indicating the ranges 
with valid data) is smaller for the VT-produced rawacf files when compared to the new 
rawacf file produced with a dattorawacf command.  This is because, as previously noted, 
there was a low power thresholding issue which was only recently fixed in the dattorawacf 
conversion routine which caused some ranges to be dropped from the rawacf file.

I also noticed the time of the first record in this particular file (14:01:24 UT) does 
not match the time as suggested from the filename (14:00:00 UT).  So I think we need to 
reprocess all of these dat files with the updated dattorawacf command (with the low-power 
thresholding disabled) and a more rigorous file naming extraction based on the first timestamp."

I was just trying to track down a few rogue CPIDs from Stokkseyri and noticed some January 
2009 RAWACF files were also produced using a dattorawacf command with low-power 
thresholding enabled (eg, 20090104.0000.00.sto.rawacf.bz2):

         string  "origin.command" = "/home/dproc/bin/dattorawacf /data1/tmp/tmp.T30861"
         ...
         string  "combf" = "$Id: fast_fte.c,v 1.01 2004/10/10 11:55:01 J.P. Villain$"
         float   "thr" = 3.000000

I'm guessing this is when the site was still using RADOPS2000 and just before the hardware 
and electronics were upgraded/replaced in 2010.  So the rawacf files from Stokkseyri for 
July 2006 to January 2009 may also need reprocessing if possible.  Would anyone still 
have the original dat files from these dates?
"

```
KKr: Need to be reprocessed with this the thresholding issues that radars are converting from 
dattorawacf on radar site. This does applies before 2006. Similarly a tool to help check the 
quality which can be done by DAWG. 

KKR: meeting end ~15:25 UTC
```